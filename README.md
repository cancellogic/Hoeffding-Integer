# Integer-Hoeffding
This is Wassley Hoeffding's 1948 equation for detecting -frequently nonlinear- relationships in data or variables.  In this version, the association value is computed with integers calculation, is not normalized (please only compare same n sample sizes) or shaped to a probability (higher values do have stronger relationships- good for detection of better models in machine learning or genetic algorithm health assessment -- but you won't know if a +81 difference is a miserable or vast improvement). Coded in Rust for generic partially ordinal types (compare {"g","e","n","e","r","i","c","s"} and {3.0,1.0,4.0,1.0,5.0,4.0,3.5,6.1})
# In defense of comprimises:
**I didn't compute the whole function.**  Roughly normalize the result if you want with division by ((n*(n-1)*(n-2)*(n-3)*(n-4))/30).  In my estimate, that undermines genetic algorthim health functions that might evolve towards models that return high normalized correlation despite being _mostly_ impossible to compute (infities, undefined, not a number, overflow, underflow)--  in a 'works great until it works against you' kind of way.  Admitedly, my thinking that Hoeffding normalization for GA is problematic is use-niche and not a formal mathmatical proof. 

**Generic functions like this one can cause slow compiles as n*n versions are made for n (every) partial ordinal type.**  For the data miner that seeks to compare apples to apples, oranges or carrots, this algorithm can.    And most published Hoeffding discriminators are not data-feed generic and mostly floating point type centeric.      

**No probability is reported.**  There seem to be about 20+ papers published in the last 60 years in this area... many claiming easy, simplified, no need for an infinite chain of perfectly random bell curve distributed data points to define the probability function for each n because Eugen Slutsky's theorm or Lorenz attractors for even odd n converge to 3 significant digits (99.9%) or something.  I didn't read more than abstracts for most.  And I understand enough of the math to know I should stop here, with unanswered questions and knowledge that a doctorate degree in number theory or statistics might be needed to proceed.   

**Faster?**  Rust is pretty fast.  Integer math is pretty fast.  This code is hopefully, fast enough for your needs - but sorting uses a lot of time in Hoeffding rankings for his correlation function.  If you are short on time, short on compute power, or certain you have a linear model - please strongly consider Pearson's R correlation (maybe crates.io/crates/ndarray-stats).  Pearsons favors linear models and isn't ideal for nonlinear GA goal seeking, but situationally, for many nonlinear models, Pearson's R correlation is good enough. 

**Am I doing the math correctly** despite obviously intended scaling/multiplication to avoid fractions and floating points?  I'm not certain of correctness, I'm outside of my expertise, and I'm not content with my own work.  If this was computing a mean, standard deviation or Pearsons R - no problem. But I do find Hoeffding's ideas beautiful and difficult.  Beware the ⇴ unicode21F4 ⇴ arrow notation, it appears to mean "Hoeffding leaves this partially defined probability function to be worked on by dozens of others for seven decades."  And even being wrong is useful.
